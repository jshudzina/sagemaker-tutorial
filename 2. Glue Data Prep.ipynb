{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep with AWS Glue\n",
    "\n",
    "While the New Times Dataset could be prepared in a notebook, this tutorial preps the dataset with Spark ML.  The spark job runs on a managed spark cluster, Amazon Glue.  Glue provides ETL (Extract, Transfom, and Load) functionality for a data warehouse.  This apporach allows for automated updates when the dataset changes.\n",
    "\n",
    "> Note: This isn't the only apporach.  The data prep could be preformed by a series of containerized micro-services and or a lambda functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-228889150161\n"
     ]
    }
   ],
   "source": [
    "#Note: We're only using the sagemaker api here to look up the S3 bucket and the exectution role.\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Glue Job\n",
    "\n",
    "In this cell, we create a glue job that runs a scala/spark script.\n",
    "\n",
    "The Job executes the following tasks.\n",
    "1. Removes HTML Markup\n",
    "2. Tokenizes the comment text. \n",
    "3. Removes stop words.\n",
    "4. Creates a vocabulary.\n",
    "5. Creates bag-of-words (i.e. word counts in the comment)\n",
    "6. Saves the bag-of-words representation in a SageMaker friendly format.\n",
    "\n",
    "The Job produces the following outputs.\n",
    "1. Vocabulary of the top N words.\n",
    "2. Sample validation data (TBD)\n",
    "3. The tranining data in a RecordIO/Protocol Buffer format.\n",
    "\n",
    "For a deeper explanation of the Bag-of-Words repersentation, see the data prepartion [this example](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/ntm_20newsgroups_topic_modeling/ntm_20newsgroups_topic_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'sagemaker-nyt-prep',\n",
       " 'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
       "   'content-length': '29',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sat, 02 Jun 2018 00:51:34 GMT',\n",
       "   'x-amzn-requestid': '18a98a2d-65ff-11e8-9a26-e3673eeba1bc'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': '18a98a2d-65ff-11e8-9a26-e3673eeba1bc',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3 \n",
    "client = boto3.client('glue')\n",
    "\n",
    "script_loc = 's3://{}/glue/nyt-comments/tokenize.scala'.format(bucket)\n",
    "sagemaker_jar = 's3://{}/glue/nyt-comments/jars/sagemaker-spark_2.11-spark_2.2.0-1.0.5.jar'.format(bucket)\n",
    "\n",
    "client.create_job(Name='sagemaker-nyt-prep',\n",
    "    Description='Spark ML job to create a bag-of-words vector',\n",
    "    Role=role,\n",
    "    Command={\n",
    "        'Name':'glueetl', \n",
    "        'ScriptLocation':script_loc},\n",
    "    DefaultArguments={\n",
    "        '--job-language': 'scala',\n",
    "        '--class': 'Tokenizer',\n",
    "        '--extra-jars': sagemaker_jar,\n",
    "        '--sagemaker_bucket': bucket\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the Job\n",
    "\n",
    "The job's status and logs are accessable via the AWS Console.\n",
    "\n",
    "![Job Status](images/GlueJobStatus.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JobRunId': 'jr_0249a7a7353017d8a2c93eb6b1b9b7b21166176640eff3a186434d89084589bf',\n",
       " 'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
       "   'content-length': '82',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sat, 02 Jun 2018 00:56:33 GMT',\n",
       "   'x-amzn-requestid': 'cb2119a0-65ff-11e8-87d5-efaa57ac0484'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': 'cb2119a0-65ff-11e8-87d5-efaa57ac0484',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.start_job_run(JobName='sagemaker-nyt-prep', \n",
    "                     AllocatedCapacity=10, \n",
    "                     Arguments={'--sagemaker_bucket': bucket})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the Labeled Dataset\n",
    "\n",
    "If a Glue crawls the jobs results ```s3://sagemaker-bucket/data/nyt-features/labeled_data.parquet```, then the labeled data is viewable via Athena.\n",
    "\n",
    "![Athena Query](images/AthenaQuery.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
